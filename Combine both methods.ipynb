{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How good will it go when we combine both methods together? \n",
    "\n",
    "### Process: \n",
    "    - Generate text as usual with the grammar finetuned GPT model\n",
    "    - Take the generated sample, split it on EOS tokens and grammar translate it with the translation model\n",
    "    - Join it again. Now we got corrected Text that has much less errors in comparison to the standard GPT model\n",
    "    - Outperforms the errorRate of the single models!\n",
    "### Observations: \n",
    "    - It works. the error rate further decreases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Number of sentences\", \"Number of wrong sentences\", \"Number of Mistakes\", \"Number of tokens\",\n",
    "          \"Errors per Token\",\"Error per sentence\",\"trashFilter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 : Check how much errors the classic model makes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_and_split_finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Combine_experiment\"\n",
    "corrected, stats = correct(data[0][:1000],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT2 base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of sentences</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of wrong sentences</th>\n",
       "      <td>359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Mistakes</th>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of tokens</th>\n",
       "      <td>33405.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errors per Token</th>\n",
       "      <td>0.019249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error per sentence</th>\n",
       "      <td>0.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trashFilter</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              GPT2 base\n",
       "Number of sentences         1000.000000\n",
       "Number of wrong sentences    359.000000\n",
       "Number of Mistakes           643.000000\n",
       "Number of tokens           33405.000000\n",
       "Errors per Token               0.019249\n",
       "Error per sentence             0.643000\n",
       "trashFilter                    0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grammar_stats(stats,len(stats[-3]) + stats[0]),index=titles,columns =[\"GPT2 base\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 : build a translation dataset from the finetuned samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = \"The Technology Report empowers or enlightens. ==== The Technology Report empowers or enlightens.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for x in data[0]: \n",
    "    examples.append( condition + \" \" + x + \"====\" + x + \"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \" \".join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"build_data/EOS_combined.txt\", \"w\",encoding = \"UTF-8\")\n",
    "f.write(examples)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step3 use the transgenerator_translation.py script to translate the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Evaluate the final translation error rate\n",
    "\n",
    "    - Finetuned 1 Epoch + 12 layer translation model\n",
    "    - Finetuned 1 Epoch + 6layer translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open(\"saves/combined.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "corrected, stats = correct_2(a,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12Layer combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of sentences</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of wrong sentences</th>\n",
       "      <td>274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Mistakes</th>\n",
       "      <td>426.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of tokens</th>\n",
       "      <td>33290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errors per Token</th>\n",
       "      <td>0.012797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error per sentence</th>\n",
       "      <td>0.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trashFilter</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           12Layer combine\n",
       "Number of sentences            1000.000000\n",
       "Number of wrong sentences       274.000000\n",
       "Number of Mistakes              426.000000\n",
       "Number of tokens              33290.000000\n",
       "Errors per Token                  0.012797\n",
       "Error per sentence                0.426000\n",
       "trashFilter                       0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grammar_stats(stats,len(stats[-3]) + stats[0]),index=titles,columns =[\"12Layer combine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pickle.load(open(\"saves/combined_6.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "corrected, stats = correct_2(b,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6Layer combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of sentences</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of wrong sentences</th>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Mistakes</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of tokens</th>\n",
       "      <td>33046.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errors per Token</th>\n",
       "      <td>0.014616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error per sentence</th>\n",
       "      <td>0.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trashFilter</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           6Layer combine\n",
       "Number of sentences           1000.000000\n",
       "Number of wrong sentences      298.000000\n",
       "Number of Mistakes             483.000000\n",
       "Number of tokens             33046.000000\n",
       "Errors per Token                 0.014616\n",
       "Error per sentence               0.483000\n",
       "trashFilter                      0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grammar_stats(stats,len(stats[-3]) + stats[0]),index=titles,columns =[\"6Layer combine\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
